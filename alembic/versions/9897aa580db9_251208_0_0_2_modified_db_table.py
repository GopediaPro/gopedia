"""251208_0.0.2_modified DB table

Revision ID: 9897aa580db9
Revises: 07aa828a0237
Create Date: 2025-12-08 00:39:34.258802

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '9897aa580db9'
down_revision: Union[str, Sequence[str], None] = '07aa828a0237'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # NOTE: Before running this migration, ensure pgvector extension is installed:
    # 1. Install pgvector: brew install pgvector (on macOS with Homebrew)
    # 2. Connect to your database and run: CREATE EXTENSION IF NOT EXISTS vector;
    # 
    # If pgvector is not installed, the embedding columns will be created as TEXT.
    # After installing pgvector, you can alter them:
    # ALTER TABLE revisions ALTER COLUMN embedding TYPE vector(1536);
    # ALTER TABLE chunk_nodes ALTER COLUMN embedding TYPE vector(1536);
    
    # 1. Create sys_dict first (referenced by other tables)
    op.create_table('sys_dict',
    sa.Column('category', sa.String(length=20), nullable=False),
    sa.Column('val', sa.Text(), nullable=False),
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('modified_at', sa.DateTime(timezone=True), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('category', 'val', name='uq_sys_dict_cat_val')
    )
    
    # 2. Create blob_store (referenced by revisions)
    op.create_table('blob_store',
    sa.Column('hash', sa.CHAR(length=64), nullable=False),
    sa.Column('content_type', sa.String(length=50), nullable=False),
    sa.Column('body', postgresql.BYTEA(), nullable=False),
    sa.PrimaryKeyConstraint('hash')
    )
    
    # 3. Create origin_data WITHOUT curr_rev_id foreign key (circular reference)
    op.create_table('origin_data',
    sa.Column('urn', sa.String(length=255), nullable=False),
    sa.Column('src_sys_id', sa.BigInteger(), nullable=False),
    sa.Column('dtype_id', sa.BigInteger(), nullable=False),
    sa.Column('props', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('flags', sa.Integer(), nullable=False),
    sa.Column('curr_rev_id', sa.BigInteger(), nullable=True),
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('modified_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['dtype_id'], ['sys_dict.id'], ),
    sa.ForeignKeyConstraint(['src_sys_id'], ['sys_dict.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('urn')
    )
    
    # 4. Create revisions (references origin_data)
    op.create_table('revisions',
    sa.Column('data_id', sa.BigInteger(), nullable=False),
    sa.Column('title', sa.String(length=512), nullable=True),
    sa.Column('summary_hash', sa.CHAR(length=64), nullable=True),
    sa.Column('tags', postgresql.ARRAY(sa.BigInteger()), nullable=True),
    sa.Column('embedding', sa.Text(), nullable=True),  # Will be changed to vector(1536) after pgvector extension is installed
    sa.Column('editor_id', sa.BigInteger(), nullable=False),
    sa.Column('meta_diff', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('modified_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['data_id'], ['origin_data.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['editor_id'], ['sys_dict.id'], ),
    sa.ForeignKeyConstraint(['summary_hash'], ['blob_store.hash'], ),
    sa.PrimaryKeyConstraint('id')
    )
    
    # 5. Add curr_rev_id foreign key to origin_data (now revisions exists)
    op.create_foreign_key(
        'fk_origin_data_curr_rev_id', 
        'origin_data', 
        'revisions', 
        ['curr_rev_id'], 
        ['id']
    )
    
    # 6. Create chunk_nodes (references revisions)
    op.create_table('chunk_nodes',
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('revision_id', sa.BigInteger(), nullable=False),
    sa.Column('chunk_hash', sa.CHAR(length=64), nullable=False),
    sa.Column('chunk_type', sa.String(length=20), nullable=True),
    sa.Column('content_summary', sa.Text(), nullable=True),
    sa.Column('embedding', sa.Text(), nullable=True),  # Will be changed to vector(1536) after pgvector extension is installed
    sa.Column('ord', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['revision_id'], ['revisions.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    
    # 7. Create knowledge_edges (references origin_data and sys_dict)
    op.create_table('knowledge_edges',
    sa.Column('source_id', sa.BigInteger(), nullable=False),
    sa.Column('target_id', sa.BigInteger(), nullable=False),
    sa.Column('predicate_id', sa.BigInteger(), nullable=False),
    sa.Column('weight', sa.Float(), nullable=False),
    sa.ForeignKeyConstraint(['predicate_id'], ['sys_dict.id'], ),
    sa.ForeignKeyConstraint(['source_id'], ['origin_data.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['target_id'], ['origin_data.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('source_id', 'target_id', 'predicate_id')
    )
    
    # 8. Create tree_nodes (references origin_data and itself)
    op.create_table('tree_nodes',
    sa.Column('parent_id', sa.BigInteger(), nullable=True),
    sa.Column('data_id', sa.BigInteger(), nullable=True),
    sa.Column('view_type', sa.String(length=20), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('slug', sa.String(length=255), nullable=False),
    sa.Column('ord', sa.Integer(), nullable=False),
    sa.Column('id', sa.BigInteger(), autoincrement=True, nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('modified_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['data_id'], ['origin_data.id'], ondelete='SET NULL'),
    sa.ForeignKeyConstraint(['parent_id'], ['tree_nodes.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('parent_id', 'slug', 'view_type', name='uq_tree_node_slug')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Drop in reverse order
    op.drop_table('tree_nodes')
    op.drop_table('knowledge_edges')
    op.drop_table('chunk_nodes')
    op.drop_constraint('fk_origin_data_curr_rev_id', 'origin_data', type_='foreignkey')
    op.drop_table('revisions')
    op.drop_table('origin_data')
    op.drop_table('blob_store')
    op.drop_table('sys_dict')
    
    # Drop pgvector extension (optional - comment out if you want to keep it)
    # op.execute('DROP EXTENSION IF EXISTS vector')
    # ### end Alembic commands ###
